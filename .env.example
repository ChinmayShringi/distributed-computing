# EdgeMesh Web Server Configuration - Example

# LLM Provider Configuration
# Set to "openai_compat" to use LM Studio or other OpenAI-compatible endpoints
LLM_PROVIDER=openai_compat

# Endpoint for the LLM service (e.g., LM Studio running locally)
LLM_ENDPOINT=http://127.0.0.1:1234

# Model identifier (must match what is loaded in LM Studio)
LLM_MODEL=qwen/qwen3-vl-8b:2
