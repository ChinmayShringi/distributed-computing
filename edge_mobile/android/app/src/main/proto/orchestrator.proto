syntax = "proto3";

package edgemesh;

option go_package = "github.com/edgecli/edgecli/proto";

service OrchestratorService {
  // Session management
  rpc CreateSession (AuthRequest) returns (SessionInfo);
  rpc Heartbeat (SessionInfo) returns (Empty);
  rpc ExecuteCommand (CommandRequest) returns (CommandResponse);

  // Device discovery and orchestration
  rpc RegisterDevice (DeviceInfo) returns (DeviceAck);
  rpc ListDevices (ListDevicesRequest) returns (ListDevicesResponse);
  rpc GetDeviceStatus (DeviceId) returns (DeviceStatus);

  // AI task routing
  rpc RunAITask (AITaskRequest) returns (AITaskResponse);

  // Connectivity check
  rpc HealthCheck (Empty) returns (HealthStatus);

  // Routed execution - forwards command to best available device
  rpc ExecuteRoutedCommand (RoutedCommandRequest) returns (RoutedCommandResponse);

  // Job orchestration (push model)
  rpc SubmitJob (JobRequest) returns (JobInfo);
  rpc GetJob (JobId) returns (JobStatus);

  // Worker execution
  rpc RunTask (TaskRequest) returns (TaskResult);

  // Plan preview (no execution)
  rpc PreviewPlan (PlanPreviewRequest) returns (PlanPreviewResponse);

  // Plan cost estimation
  rpc PreviewPlanCost (PlanCostRequest) returns (PlanCostResponse);

  // WebRTC screen streaming
  rpc StartWebRTC (WebRTCConfig) returns (WebRTCOffer);
  rpc CompleteWebRTC (WebRTCAnswer) returns (Empty);
  rpc StopWebRTC (WebRTCStop) returns (Empty);

  // File download ticket
  rpc CreateDownloadTicket (DownloadTicketRequest) returns (DownloadTicketResponse);

  // File reading (for LLM tool calling)
  rpc ReadFile (ReadFileRequest) returns (ReadFileResponse);

  // Chat memory synchronization
  rpc SyncChatMemory (ChatMemorySync) returns (ChatMemorySyncResponse);
  rpc GetChatMemory (Empty) returns (ChatMemoryData);

  // Remote LLM task execution
  rpc RunLLMTask (LLMTaskRequest) returns (LLMTaskResponse);

  // Activity tracking and metrics
  rpc GetActivity (GetActivityRequest) returns (GetActivityResponse);
  rpc GetDeviceMetrics (DeviceId) returns (MetricsHistoryResponse);
  rpc GetJobDetail (JobId) returns (JobDetailResponse);
}

message Empty {}

message AuthRequest {
  string device_name = 1;
  string security_key = 2;
}

message SessionInfo {
  string session_id = 1;
  string host_name = 2;
  int64 connected_at = 3;
}

message CommandRequest {
  string session_id = 1;
  string command = 2;
  repeated string args = 3;
}

message CommandResponse {
  int32 exit_code = 1;
  string stdout = 2;
  string stderr = 3;
}

// Device discovery messages

message DeviceId {
  string device_id = 1;
}

message DeviceInfo {
  string device_id = 1;    // stable id generated by device at first run (uuid stored on disk)
  string device_name = 2;  // "chinmay-mac", "windows-laptop", etc
  string platform = 3;     // "macos", "windows", "linux", "android"
  string arch = 4;         // "amd64", "arm64"
  bool has_cpu = 5;        // always true
  bool has_gpu = 6;
  bool has_npu = 7;        // false for now, will be true on Snapdragon later
  string grpc_addr = 8;    // where this device can be reached, e.g. "10.0.0.5:50051"
  bool can_screen_capture = 9;  // true if device can capture screen (tested at startup)
  string http_addr = 10;  // bulk HTTP server address, e.g. "10.0.0.5:8081"
  // LLM inference throughput (for cost estimation)
  double llm_prefill_toks_per_s = 11;  // 0 = use platform default
  double llm_decode_toks_per_s = 12;   // 0 = use platform default
  uint64 ram_free_mb = 13;              // free RAM in MB (0 = unknown)
  // Local LLM model capability
  bool has_local_model = 14;           // device has Ollama/chat running
  string local_model_name = 15;        // loaded model (e.g., "llama3.2:3b")
  string local_chat_endpoint = 16;     // URL to chat service (e.g., "http://192.168.1.38:11434")
}

message DeviceAck {
  bool ok = 1;
  int64 registered_at = 2;  // unix seconds
}

message DeviceStatus {
  string device_id = 1;
  int64 last_seen = 2;      // unix seconds
  double cpu_load = 3;      // 0..1, or -1 if unavailable
  uint64 mem_used_mb = 4;
  uint64 mem_total_mb = 5;
  // GPU/NPU metrics for activity tracking
  double gpu_load = 6;            // 0..1, or -1 if unavailable
  uint64 gpu_mem_used_mb = 7;
  uint64 gpu_mem_total_mb = 8;
  double npu_load = 9;            // 0..1, or -1 if unavailable
  int64 timestamp_ms = 10;        // sample timestamp (unix milliseconds)
}

message ListDevicesRequest {}

message ListDevicesResponse {
  repeated DeviceInfo devices = 1;
}

// AI task routing messages

message AITaskRequest {
  string session_id = 1;
  string task = 2;   // "summarize", "transcribe", "analyze_screen"
  string input = 3;  // for now, just raw text
}

message AITaskResponse {
  string selected_device_id = 1;
  string selected_device_addr = 2;
  bool would_use_npu = 3;
  string result = 4;  // stub result: "ROUTED: <task> to <device_name>"
}

// Health check messages

message HealthStatus {
  string device_id = 1;    // server's device ID (may be empty if not configured)
  int64 server_time = 2;   // unix seconds
  string message = 3;      // "ok"
}

// Routed execution messages

message RoutingPolicy {
  enum Mode {
    BEST_AVAILABLE = 0;    // prefer NPU, then GPU, then CPU
    REQUIRE_NPU = 1;       // fail if no NPU device
    PREFER_REMOTE = 2;     // prefer not-self if possible
    FORCE_DEVICE_ID = 3;   // require specific device_id
    PREFER_LOCAL_MODEL = 4;   // prefer device with local LLM model
    REQUIRE_LOCAL_MODEL = 5;  // fail if no local LLM model available
  }
  Mode mode = 1;
  string device_id = 2;    // used if FORCE_DEVICE_ID
}

message RoutedCommandRequest {
  string session_id = 1;
  RoutingPolicy policy = 2;
  string command = 3;
  repeated string args = 4;
}

message RoutedCommandResponse {
  CommandResponse output = 1;
  string selected_device_id = 2;
  string selected_device_name = 3;
  string selected_device_addr = 4;
  double total_time_ms = 5;       // includes forwarding overhead
  bool executed_locally = 6;      // true if ran on the coordinator itself
}

// Job orchestration messages

message JobId {
  string job_id = 1;
}

message JobRequest {
  string session_id = 1;
  string text = 2;           // user request description
  int32 max_workers = 3;     // 0 = use all available devices
  Plan plan = 4;             // optional: explicit execution plan
  ReduceSpec reduce = 5;     // optional: how to combine results
}

// Planning structures
message Plan {
  repeated TaskGroup groups = 1;  // groups execute sequentially
}

message TaskGroup {
  int32 index = 1;               // execution order (0 = first)
  repeated TaskSpec tasks = 2;   // tasks in group run in parallel
}

message TaskSpec {
  string task_id = 1;
  string kind = 2;               // "SYSINFO", "ECHO", "LLM_GENERATE", etc.
  string input = 3;
  string target_device_id = 4;   // empty = let orchestrator assign
  // LLM_GENERATE parameters (for cost estimation)
  int32 prompt_tokens = 5;       // estimated prompt tokens
  int32 max_output_tokens = 6;   // max output tokens to generate
}

message ReduceSpec {
  string kind = 1;               // "CONCAT" for now
}

message JobInfo {
  string job_id = 1;
  int64 created_at = 2;
  string summary = 3;        // e.g. "distributed to N devices"
}

message JobStatus {
  string job_id = 1;
  string state = 2;          // QUEUED, RUNNING, DONE, FAILED
  repeated TaskStatus tasks = 3;
  string final_result = 4;   // concatenated results when DONE
  int32 current_group = 5;   // which group is currently executing
  int32 total_groups = 6;    // total number of groups in plan
}

message TaskStatus {
  string task_id = 1;
  string assigned_device_id = 2;
  string assigned_device_name = 3;
  string state = 4;          // QUEUED, RUNNING, DONE, FAILED
  string result = 5;
  string error = 6;
}

message TaskRequest {
  string task_id = 1;
  string job_id = 2;
  string kind = 3;           // "ECHO" or "SYSINFO"
  string input = 4;
}

message TaskResult {
  string task_id = 1;
  bool ok = 2;
  string output = 3;
  string error = 4;
  double time_ms = 5;
}

// WebRTC streaming messages

message WebRTCConfig {
  string session_id = 1;
  int32 target_fps = 2;           // default 8 if 0
  int32 jpeg_quality = 3;         // default 60 if 0
  int32 monitor_index = 4;        // default 0
}

message WebRTCOffer {
  string stream_id = 1;
  string sdp = 2;                 // offer SDP including ICE candidates (non-trickle)
}

message WebRTCAnswer {
  string stream_id = 1;
  string sdp = 2;                 // answer SDP including ICE candidates (non-trickle)
}

message WebRTCStop {
  string stream_id = 1;
}

// Plan preview messages

message PlanPreviewRequest {
  string session_id = 1;
  string text = 2;
  int32 max_workers = 3;
}

message PlanPreviewResponse {
  bool used_ai = 1;
  string notes = 2;
  string rationale = 3;
  Plan plan = 4;
  ReduceSpec reduce = 5;
}

// Plan cost estimation messages

message PlanCostRequest {
  string session_id = 1;
  Plan plan = 2;                      // plan to estimate
  repeated string device_ids = 3;     // optional: limit to these devices (empty = all)
}

message PlanCostResponse {
  double total_predicted_ms = 1;               // best device's total latency
  repeated DeviceCostEstimate device_costs = 2;
  string recommended_device_id = 3;
  string recommended_device_name = 4;
  bool has_unknown_costs = 5;                  // true if any step had unknown cost
  string warning = 6;                          // warning message if applicable
}

message DeviceCostEstimate {
  string device_id = 1;
  string device_name = 2;
  double total_ms = 3;
  repeated StepCostEstimate step_costs = 4;
  uint64 estimated_peak_ram_mb = 5;
  bool ram_sufficient = 6;                     // false if estimated RAM > device free RAM
}

message StepCostEstimate {
  string task_id = 1;
  string kind = 2;
  double predicted_ms = 3;
  double predicted_memory_mb = 4;
  bool unknown_cost = 5;                       // true if step type not recognized
  string notes = 6;                            // e.g., "using default prefill TPS"
}

// File download messages

message DownloadTicketRequest {
  string path = 1;  // relative path under shared root, e.g. "test.txt"
}

message DownloadTicketResponse {
  string token = 1;              // one-time-use download token
  string filename = 2;           // basename of the file
  int64 size_bytes = 3;          // file size
  int64 expires_unix_ms = 4;     // absolute expiry (ms since epoch)
}

// File reading messages (for LLM tool calling)

enum ReadMode {
  READ_MODE_FULL = 0;
  READ_MODE_HEAD = 1;
  READ_MODE_TAIL = 2;
  READ_MODE_RANGE = 3;
}

message ReadFileRequest {
  string session_id = 1;
  string device_id = 2;      // target device (empty = local)
  string path = 3;
  ReadMode mode = 4;
  int32 max_bytes = 5;       // default 65536, max 10MB
  int64 offset = 6;          // for RANGE mode
  int64 length = 7;          // for RANGE mode
}

message ReadFileResponse {
  bytes content = 1;
  int64 size_bytes = 2;      // actual file size
  int64 bytes_returned = 3;  // bytes returned in content
  bool truncated = 4;
  string error = 5;
  string content_preview = 6;  // first ~2KB decoded if text
}

// Chat memory synchronization messages

message ChatMemorySync {
  int64 last_updated_ms = 1;   // timestamp of sender's memory
  string memory_json = 2;       // full JSON if pushing, empty if pulling
}

message ChatMemorySyncResponse {
  bool updated = 1;             // true if receiver's memory was updated
  string memory_json = 2;       // new JSON if updated, empty otherwise
}

message ChatMemoryData {
  string memory_json = 1;       // full chat memory JSON
}

// Remote LLM task messages

message LLMTaskRequest {
  string prompt = 1;
  string model = 2;        // optional: specific model name
  int32 max_tokens = 3;    // optional: max tokens to generate
}

message LLMTaskResponse {
  string output = 1;
  string model_used = 2;
  int64 tokens_generated = 3;
  string error = 4;
}

// Activity tracking messages

message MetricsSample {
  int64 timestamp_ms = 1;
  double cpu_load = 2;
  uint64 mem_used_mb = 3;
  uint64 mem_total_mb = 4;
  double gpu_load = 5;
  uint64 gpu_mem_used_mb = 6;
  uint64 gpu_mem_total_mb = 7;
  double npu_load = 8;
}

message RunningTask {
  string task_id = 1;
  string job_id = 2;
  string kind = 3;
  string input = 4;
  string device_id = 5;
  string device_name = 6;
  int64 started_at_ms = 7;
  int64 elapsed_ms = 8;
}

message DeviceActivity {
  string device_id = 1;
  string device_name = 2;
  int32 running_task_count = 3;
  DeviceStatus current_status = 4;
}

message ActivityData {
  repeated RunningTask running_tasks = 1;
  repeated DeviceActivity device_activities = 2;
}

message GetActivityRequest {
  bool include_metrics_history = 1;
  int64 metrics_since_ms = 2;
}

message MetricsHistoryResponse {
  string device_id = 1;
  string device_name = 2;
  repeated MetricsSample samples = 3;
}

message GetActivityResponse {
  ActivityData activity = 1;
  map<string, MetricsHistoryResponse> device_metrics = 2;
}

// Enhanced task status for visualization
message TaskStatusEnhanced {
  string task_id = 1;
  string job_id = 2;
  string assigned_device_id = 3;
  string assigned_device_name = 4;
  string kind = 5;
  string input = 6;
  string state = 7;
  string result = 8;
  string error = 9;
  int32 group_index = 10;
  int64 started_at_ms = 11;
  int64 ended_at_ms = 12;
}

message JobDetailResponse {
  string job_id = 1;
  string state = 2;
  repeated TaskStatusEnhanced tasks = 3;
  string final_result = 4;
  int32 current_group = 5;
  int32 total_groups = 6;
  int64 created_at_ms = 7;
  int64 started_at_ms = 8;
  int64 ended_at_ms = 9;
}
